# Advanced Hybrid RAG Application (v2)

A comprehensive RAG application with hybrid search, document summarization, metadata enrichment, and local LLM support.

## Features

- **âœ¨ Hybrid Search**: Combines sparse (BM25-style) and dense (semantic) embeddings for optimal retrieval
- **ğŸ“ Document Summarization**: Automatic generation of document summaries for quick insights
- **ğŸ·ï¸ Metadata Enrichment**: Automated extraction of entities, topics, and structured metadata
- **ğŸ¤– Local LLM**: Uses Ollama for private, offline inference
- **â˜ï¸ Qdrant Storage**: Persistent cloud-based vector storage with hybrid capabilities
- **ğŸ“Š Rich Statistics**: Document analytics and search quality metrics

## Architecture

### Indexing Pipeline
```
Documents â†’ Splitter â†’ Metadata Enricher â†’ Summarizer â†’ Dense Embedder â†’ Sparse Embedder â†’ Qdrant
```

### Query Pipeline
```
Query â†’ Dense Embedder â†’ Sparse Embedder â†’ Hybrid Retriever â†’ Reranker â†’ Prompt Builder â†’ LLM Generator
```

## Requirements

- Python 3.9+
- Qdrant Cloud account
- Ollama installed and running locally
- At least 8GB RAM recommended

## Setup

### Option 1: Using Poetry (Recommended)

1. Install Poetry if you haven't already:
```bash
pip install poetry
```

2. Install dependencies:
```bash
poetry install
```

3. Activate the virtual environment:
```bash
poetry shell
```

### Option 2: Using pip

1. Install dependencies:
```bash
pip install -r requirements.txt
```
**With Poetry:**
```bash
poetry run index-docs
# or
poetry run python index_documents.py
```

**With pip:**

2. Configure environment variables in `.env`:
```
QDRANT_ENDPOINT=your_qdrant_url
QDRANT_API_KEY=your_api_key
OLLAMA_URL=http://127.0.0.1:11435
OLLAMA_MODEL=llama3.1:8b
```

3. Start Ollama:
```bash
ollama serve
ollama pull llama3.1:8b
```

## Usage

### 1. Index Documents

**With Poetry:**
```bash
poetry run python scripts/index_documents.py
```

**Direct:**
```bash
python scripts/index_documents.py
```

This will:
- Load documents from `data/documents_ro/`
- Extract metadata and entities
- Generate summaries for each chunk
- Create both dense and sparse embeddings
- Store everything in Qdrant

### 2. Query Documents

**With Poetry:**
```bash
poetry run python query_app.py
# or provide query directly
poetry run python query_app.py "facturi sub 1000 lei"
```

**Direct:**
```bash
python query_app.py
```

Interactive query interface with:
- Hybrid search (configurable weights)
- Context from summaries
- Metadata filtering
- Source citation

### 3. Run Evaluation

**With Poetry:**
```bash
poetry run python evaluation/run_evaluation.py
```

This will:
- Run predefined test queries
- Score metadata extraction, filter usage, and retrieval quality
- Track results in Langfuse
- Save results to `evaluation/results/`

### 4. Manage Qdrant Indexes

**Create payload indexes:**
```bash
poetry run python scripts/create_payload_indexes.py
```

**Recreate entire collection:**
```bash
poetry run python scripts/recreate_collection.py
```

**Check indexed data:**
```bash
poetry run python scripts/test_check_data.py
```

## Configuration

Edit `config.py` to customize:
- Embedding models
- Chunk sizes
- Retrieval parameters
- Summarization settings
- Metadata extraction prompts

## Metadata Enrichment

Automatically extracted metadata includes:
- **Entities**: Companies, people, locations, dates
- **Topics**: Main subjects and themes
- **Document Type**: Contracts, reports, emails, etc.
- **Language**: Detected language
- **Keywords**: Important terms

## Summarization

Each document chunk gets:
- **Brief Summary**: 1-2 sentences
- **Key Points**: Bullet points of main ideas
- **Context**: Surrounding document context

## Hybrid Search Explained

Combines two retrieval methods:
1. **Sparse Embeddings**: Keyword/term matching (like BM25)
2. **Dense Embeddings**: Semantic similarity

You can adjust the balance between them for your use case:
- More sparse weight â†’ Better for exact matches
- More dense weight â†’ Better for conceptual queries

## Project Structure

```
app_v2/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pyproject.toml              # Poetry configuration
â”œâ”€â”€ query_app.py                # Interactive query interface (entry point)
â”‚
â”œâ”€â”€ src/                        # Core application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                  # Main RAG application class
â”‚   â”œâ”€â”€ config.py               # Configuration settings
â”‚   â”œâ”€â”€ langfuse_tracker.py     # Langfuse observability
â”‚   â””â”€â”€ utils.py                # Utility functions
â”‚
â”œâ”€â”€ components/                 # Custom Haystack components
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ semantic_chunker.py     # Semantic document chunking
â”‚   â”œâ”€â”€ metadata_enricher.py    # Metadata extraction
â”‚   â”œâ”€â”€ document_type_detector.py  # Document type detection
â”‚   â”œâ”€â”€ query_metadata_extractor.py  # Query filter extraction
â”‚   â”œâ”€â”€ boilerplate_filter.py   # Boilerplate detection
â”‚   â””â”€â”€ summarizer.py           # Document summarization
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ README.md               # Scripts documentation
â”‚   â”œâ”€â”€ index_documents.py      # Index documents to Qdrant
â”‚   â”œâ”€â”€ create_payload_indexes.py  # Create metadata indexes
â”‚   â”œâ”€â”€ recreate_collection.py  # Recreate Qdrant collection
â”‚   â”œâ”€â”€ cleanup_old_indexes.py  # Clean up old indexes
â”‚   â”œâ”€â”€ debug_section_type.py   # Debug section_type filter
â”‚   â””â”€â”€ test_check_data.py      # Quick data check
â”‚
â”œâ”€â”€ evaluation/                 # Evaluation system
â”‚   â”œâ”€â”€ README.md               # Evaluation documentation
â”‚   â”œâ”€â”€ evaluation_dataset.py   # Test queries and expected outputs
â”‚   â”œâ”€â”€ run_evaluation.py       # Automated evaluation runner
â”‚   â””â”€â”€ results/                # Evaluation results
â”‚
â”œâ”€â”€ verify_check/               # Testing and debugging scripts
â”‚   â”œâ”€â”€ test_structured_qa.py
â”‚   â”œâ”€â”€ test_hybrid_retrieval.py
â”‚   â””â”€â”€ ... (other test scripts)
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ EVALUATION.md
â”‚   â”œâ”€â”€ LANGFUSE_SETUP.md
â”‚   â””â”€â”€ ... (other docs)
â”‚
â”œâ”€â”€ prompts/                    # LLM prompts
â”‚   â”œâ”€â”€ rag_system.txt
â”‚   â”œâ”€â”€ metadata_extraction.txt
â”‚   â”œâ”€â”€ query_extraction.txt
â”‚   â””â”€â”€ ... (other prompts)
â”‚
â”œâ”€â”€ data/                       # Data directory
â”‚   â”œâ”€â”€ documents_ro/           # Documents to index
â”‚   â””â”€â”€ documents_ro_v1/
â”‚
â”œâ”€â”€ logs/                       # Application logs
â””â”€â”€ notebooks/                  # Jupyter notebooks
    â”œâ”€â”€ hybrid_retrieval_bm42.ipynb
    â””â”€â”€ ... (other notebooks)
```

## Performance Tips

1. **GPU Acceleration**: Set `device='cuda'` for embedders if you have a GPU
2. **Batch Processing**: Increase batch sizes for faster indexing
3. **Ollama Performance**: Use quantized models (e.g., `llama3.1:8b-q4_0`) for faster inference
4. **Qdrant Optimization**: Enable compression in Qdrant for storage efficiency

## Troubleshooting

### Ollama Connection Issues
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Restart Ollama
ollama serve
```

### Qdrant Connection Issues
- Verify credentials in `.env`
- Check network connectivity
- Confirm collection exists

### Out of Memory
- Reduce `batch_size` in config
- Use smaller embedding models
- Process documents in smaller batches

## License

MIT License - See main repository for details
